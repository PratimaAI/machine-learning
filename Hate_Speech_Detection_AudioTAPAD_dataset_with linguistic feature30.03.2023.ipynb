{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "740bec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c922b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "from pydub import AudioSegment\n",
    "import speech_recognition as sr\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a8da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e4075eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the audio files and create a DataFrame\n",
    "audio_dir = 'audio'  # Replace with the path to your audio folder\n",
    "audio_files = os.listdir(audio_dir)\n",
    "audio_df = pd.DataFrame({'filename': audio_files, 'filepath': [os.path.join(audio_dir, f) for f in audio_files]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03ef5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['af', 'ar', 'bn', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'desktop.ini', 'el', 'en', 'en-au', 'en-ca', 'en-gb', 'en-gh', 'en-ie', 'en-in', 'en-ng', 'en-nz', 'en-ph', 'en-tz', 'en-uk', 'en-us', 'en-za', 'eo', 'es', 'es-es', 'es-us', 'et', 'fi', 'fr', 'fr-ca', 'fr-fr', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jw', 'km', 'ko', 'la', 'lv', 'mk', 'ml', 'mr', 'my', 'ne', 'nl', 'no', 'pl', 'pt', 'pt-br', 'pt-pt', 'ro', 'ru', 'si', 'sk', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'vi', 'zh-cn', 'zh-tw']\n"
     ]
    }
   ],
   "source": [
    "print(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b57cd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>af</td>\n",
       "      <td>audio\\af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ar</td>\n",
       "      <td>audio\\ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bn</td>\n",
       "      <td>audio\\bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bs</td>\n",
       "      <td>audio\\bs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca</td>\n",
       "      <td>audio\\ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>tr</td>\n",
       "      <td>audio\\tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>uk</td>\n",
       "      <td>audio\\uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>vi</td>\n",
       "      <td>audio\\vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>zh-cn</td>\n",
       "      <td>audio\\zh-cn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>zh-tw</td>\n",
       "      <td>audio\\zh-tw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   filename     filepath\n",
       "0        af     audio\\af\n",
       "1        ar     audio\\ar\n",
       "2        bn     audio\\bn\n",
       "3        bs     audio\\bs\n",
       "4        ca     audio\\ca\n",
       "..      ...          ...\n",
       "71       tr     audio\\tr\n",
       "72       uk     audio\\uk\n",
       "73       vi     audio\\vi\n",
       "74    zh-cn  audio\\zh-cn\n",
       "75    zh-tw  audio\\zh-tw\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b68c324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "# Define the directory where your audio files are located\n",
    "audio_dir = 'audio'\n",
    "\n",
    "# Create a list of all audio file paths in the directory\n",
    "audio_files = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith('.mp3')]\n",
    "\n",
    "# Define a function to extract acoustic features\n",
    "def extract_acoustic_features(audio_file_path):\n",
    "    y, sr = librosa.load(audio_file_path, sr=None)\n",
    "    chroma_stft_mean = librosa.feature.chroma_stft(y=y, sr=sr).mean()\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "    return chroma_stft_mean, rmse[0][0], spectral_centroid[0][0], spectral_bandwidth[0][0], rolloff[0][0], zero_crossing_rate[0][0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "788c0b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Advanced ML Final Project Code.ipynb', 'audio', 'audio_features.csv', 'HateSpeechDetectionText_EPOCH 1.ipynb', 'HateSpeechDetection_TextDataset.ipynb', 'Hate_Speech_Detection_AudioTAPAD_dataset-20.03.2023.ipynb', 'Hate_Speech_Detection_AudioTAPAD_dataset.ipynb', 'Sid.ipynb', 'Untitled.ipynb', 'Untitled1.ipynb']\n"
     ]
    }
   ],
   "source": [
    "audio_dir = 'audio'  # Replace with the path to your audio folder\n",
    "print(os.listdir())\n",
    "audio_files = os.listdir(audio_dir)\n",
    "audio_df = pd.DataFrame({'filename': audio_files, 'filepath': [os.path.join(audio_dir, f) for f in audio_files]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0bdd8ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['af', 'ar', 'bn', 'bs', 'ca', 'cs', 'cy', 'da', 'de', 'desktop.ini', 'el', 'en', 'en-au', 'en-ca', 'en-gb', 'en-gh', 'en-ie', 'en-in', 'en-ng', 'en-nz', 'en-ph', 'en-tz', 'en-uk', 'en-us', 'en-za', 'eo', 'es', 'es-es', 'es-us', 'et', 'fi', 'fr', 'fr-ca', 'fr-fr', 'hi', 'hr', 'hu', 'hy', 'id', 'is', 'it', 'ja', 'jw', 'km', 'ko', 'la', 'lv', 'mk', 'ml', 'mr', 'my', 'ne', 'nl', 'no', 'pl', 'pt', 'pt-br', 'pt-pt', 'ro', 'ru', 'si', 'sk', 'sq', 'sr', 'su', 'sv', 'sw', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'vi', 'zh-cn', 'zh-tw']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "audio_dir = \"./audio\"\n",
    "print(os.listdir(audio_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d7c7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             filename                   filepath  chroma_stft_mean      rmse  \\\n",
      "0            anus.mp3          audio\\af\\anus.mp3          0.461504  0.000172   \n",
      "1            arse.mp3          audio\\af\\arse.mp3          0.448611  0.000000   \n",
      "2        arsehole.mp3      audio\\af\\arsehole.mp3          0.470297  0.000000   \n",
      "3         ass-hat.mp3       audio\\af\\ass-hat.mp3          0.450537  0.000161   \n",
      "4      ass-jabber.mp3    audio\\af\\ass-jabber.mp3          0.442178  0.000168   \n",
      "...               ...                        ...               ...       ...   \n",
      "26020     wetback.mp3    audio\\zh-tw\\wetback.mp3          0.310399  0.000008   \n",
      "26021       whore.mp3      audio\\zh-tw\\whore.mp3          0.430026  0.000013   \n",
      "26022    whorebag.mp3   audio\\zh-tw\\whorebag.mp3          0.313372  0.000007   \n",
      "26023   whoreface.mp3  audio\\zh-tw\\whoreface.mp3          0.268046  0.000007   \n",
      "26024         wop.mp3        audio\\zh-tw\\wop.mp3          0.356107  0.000012   \n",
      "\n",
      "       spectral_centroid  spectral_bandwidth      rolloff  zero_crossing_rate  \n",
      "0            1872.055975         1311.263929  3542.211914            0.091797  \n",
      "1               0.000000            0.000000     0.000000            0.000000  \n",
      "2               0.000000            0.000000     0.000000            0.000000  \n",
      "3            1969.299497         1305.907948  3520.678711            0.079590  \n",
      "4            1900.477121         1272.574038  3520.678711            0.099121  \n",
      "...                  ...                 ...          ...                 ...  \n",
      "26020        3504.981003         2410.346625  6395.361328            0.193848  \n",
      "26021        3356.307593         2314.871363  5512.500000            0.151855  \n",
      "26022        3638.078277         2390.311339  6330.761719            0.185059  \n",
      "26023        3637.914217         2390.262973  6330.761719            0.184082  \n",
      "26024        3698.779141         2486.959027  6664.526367            0.178223  \n",
      "\n",
      "[26025 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of all audio file paths in the \"audio\" folder and its subdirectories\n",
    "audio_files = []\n",
    "for root, dirs, files in os.walk('audio'):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp3'):\n",
    "            audio_files.append(os.path.join(root, file))\n",
    "\n",
    "# Create a DataFrame with the audio file names and their acoustic features\n",
    "audio_data = {'filename': [], 'filepath': [], 'chroma_stft_mean': [], 'rmse': [], 'spectral_centroid': [], 'spectral_bandwidth': [], 'rolloff': [], 'zero_crossing_rate': []}\n",
    "for audio_file in audio_files:\n",
    "    audio_data['filename'].append(os.path.basename(audio_file))\n",
    "    audio_data['filepath'].append(audio_file)\n",
    "    features = extract_acoustic_features(audio_file)\n",
    "    for i, feature_name in enumerate(['chroma_stft_mean', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate']):\n",
    "        audio_data[feature_name].append(features[i])\n",
    "\n",
    "acoustic_df = pd.DataFrame(audio_data)\n",
    "print(acoustic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19871bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5516ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "import spacy\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Define a function to extract text from audio files\n",
    "def extract_text(audio_path):\n",
    "    # Convert audio to WAV format using FFmpeg\n",
    "    wav_path = os.path.splitext(audio_path)[0] + \".wav\"\n",
    "    subprocess.run(['ffmpeg', '-i', audio_path, '-vn', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', wav_path], check=True)\n",
    "    \n",
    "    # Transcribe audio to text using Google Speech Recognition\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(wav_path) as source:\n",
    "        audio = r.record(source)\n",
    "    text = r.recognize_google(audio)\n",
    "    \n",
    "    # Remove the temporary WAV file\n",
    "    os.remove(wav_path)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9ca7bfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linguistic_features(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Use spaCy to extract linguistic features from the text\n",
    "    doc = nlp(text)\n",
    "    features = {\n",
    "        \"num_sentences\": len(list(doc.sents)),\n",
    "        \"num_words\": len(doc),\n",
    "        \"num_unique_words\": len(set([token.text.lower() for token in doc if token.is_alpha])),\n",
    "        \"avg_word_length\": sum([len(token.text) for token in doc if token.is_alpha]) / len([token for token in doc if token.is_alpha]),\n",
    "        \"num_stopwords\": len([token for token in doc if token.is_stop]),\n",
    "        \"avg_sentence_length\": len(doc) / len(list(doc.sents)),\n",
    "        \"num_nouns\": len([token for token in doc if token.pos_ == \"NOUN\"]),\n",
    "        \"num_verbs\": len([token for token in doc if token.pos_ == \"VERB\"]),\n",
    "        \"num_adjectives\": len([token for token in doc if token.pos_ == \"ADJ\"]),\n",
    "        \"num_adverbs\": len([token for token in doc if token.pos_ == \"ADV\"]),\n",
    "        \"num_pronouns\": len([token for token in doc if token.pos_ == \"PRON\"]),\n",
    "        \"num_proper_nouns\": len([token for token in doc if token.pos_ == \"PROPN\"]),\n",
    "        \"num_conjunctions\": len([token for token in doc if token.pos_ == \"CCONJ\" or token.pos_ == \"SCONJ\"]),\n",
    "        \"num_numerals\": len([token for token in doc if token.pos_ == \"NUM\"]),\n",
    "        \"num_particles\": len([token for token in doc if token.pos_ == \"PART\"]),\n",
    "        \"num_punctuations\": len([token for token in doc if token.pos_ == \"PUNCT\"]),\n",
    "        \"num_symbols\": len([token for token in doc if token.pos_ == \"SYM\"])\n",
    "    }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "690e1268",
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ffmpeg', '-i', 'audio/af/anus.mp3', '-vn', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', 'audio/af/anus.wav']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9308\\2588850830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Replace any backslashes with forward slashes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# Extract the text from the mp3 file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Extract the linguistic features from the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_linguistic_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9308\\3551958668.py\u001b[0m in \u001b[0;36mextract_text\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# Convert audio to WAV format using FFmpeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mwav_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".wav\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ffmpeg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-vn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-acodec'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pcm_s16le'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-ac'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-ar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'16000'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwav_path\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Transcribe audio to text using Google Speech Recognition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[0;32m    529\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-i', 'audio/af/anus.mp3', '-vn', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', 'audio/af/anus.wav']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# Set the path to your audio folder\n",
    "audio_folder = 'audio'\n",
    "\n",
    "# Create an empty DataFrame to store the linguistic features for each file\n",
    "#linguistic_features_df = pd.DataFrame(columns=['file_name', 'noun_chunks', 'num_sentences', 'num_tokens', 'avg_token_length', 'avg_sentence_length', 'num_stopwords', 'num_punctuations', 'num_entities'])\n",
    "\n",
    "# Loop over each subdirectory in the audio folder\n",
    "for root, dirs, files in os.walk(audio_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp3'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_path = file_path.replace(\"\\\\\", \"/\") # Replace any backslashes with forward slashes\n",
    "            # Extract the text from the mp3 file\n",
    "            text = extract_text(file_path)\n",
    "            # Extract the linguistic features from the text\n",
    "            features = extract_linguistic_features(text)\n",
    "            # Add the file name to the features DataFrame\n",
    "            features['file_name'] = file\n",
    "            # Append the features to the DataFrame\n",
    "            linguistic_features_df = linguistic_features_df.append(features, ignore_index=True)\n",
    "\n",
    "            print(file_path)\n",
    "            print(text)\n",
    "# Save the DataFrame to a CSV file\n",
    "#linguistic_features_df.to_csv('linguistic_features.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e155b242",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownValueError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9308\\1403705506.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;31m# Extract the linguistic features from the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mraise\u001b[0m \u001b[0mUnknownValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"confidence\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactual_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alternative\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import speech_recognition as sr\n",
    "import spacy\n",
    "\n",
    "# Set the path to your audio folder\n",
    "audio_folder = 'audio'\n",
    "\n",
    "# Create an empty DataFrame to store the linguistic features for each file\n",
    "linguistic_features_df = pd.DataFrame(columns=['file_name', 'noun_chunks', 'num_sentences', 'num_tokens', 'avg_token_length', 'avg_sentence_length', 'num_stopwords', 'num_punctuations', 'num_entities'])\n",
    "\n",
    "# Loop over each subdirectory in the audio folder\n",
    "for root, dirs, files in os.walk(audio_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.mp3'):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_path = file_path.replace(\"\\\\\", \"/\") # Replace any backslashes with forward slashes\n",
    "            # Convert the mp3 file to a WAV file\n",
    "            wav_path = os.path.join(root, os.path.splitext(file)[0] + '.wav')\n",
    "            os.system(f'ffmpeg -i \"{file_path}\" -vn -acodec pcm_s16le -ac 1 -ar 16000 \"{wav_path}\"')\n",
    "            # Extract the text from the WAV file\n",
    "            r = sr.Recognizer()\n",
    "            with sr.AudioFile(wav_path) as source:\n",
    "                audio = r.record(source)\n",
    "            text = r.recognize_google(audio)\n",
    "            # Extract the linguistic features from the text\n",
    "            nlp = spacy.load('en_core_web_sm')\n",
    "            doc = nlp(text)\n",
    "            noun_chunks = [chunk.text for chunk in doc.noun_chunks]\n",
    "            num_sentences = len(list(doc.sents))\n",
    "            num_tokens = len(doc)\n",
    "            avg_token_length = sum(len(token.text) for token in doc) / num_tokens\n",
    "            avg_sentence_length = num_tokens / num_sentences\n",
    "            num_stopwords = len([token for token in doc if token.is_stop])\n",
    "            num_punctuations = len([token for token in doc if token.is_punct])\n",
    "            num_entities = len(doc.ents)\n",
    "            # Add the file name and linguistic features to the DataFrame\n",
    "            features = {\n",
    "                'file_name': file,\n",
    "                'noun_chunks': noun_chunks,\n",
    "                'num_sentences': num_sentences,\n",
    "                'num_tokens': num_tokens,\n",
    "                'avg_token_length': avg_token_length,\n",
    "                'avg_sentence_length': avg_sentence_length,\n",
    "                'num_stopwords': num_stopwords,\n",
    "                'num_punctuations': num_punctuations,\n",
    "                'num_entities': num_entities\n",
    "            }\n",
    "            linguistic_features_df = linguistic_features_df.append(features, ignore_index=True)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "linguistic_features_df.to_csv('linguistic_features.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "852e7790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def extract_text_from_mp3(mp3_path):\n",
    "    # Initialize a recognizer object\n",
    "    r = sr.Recognizer()\n",
    "    \n",
    "    # Load the audio file and transcribe the speech to text\n",
    "    with sr.AudioFile(mp3_path) as source:\n",
    "        audio_data = r.record(source)\n",
    "        text = r.recognize_google(audio_data)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the root folder\n",
    "root_folder = 'audio'\n",
    "\n",
    "# Define a list to store the extracted texts\n",
    "texts = []\n",
    "\n",
    "# Traverse the folder structure and extract text from all MP3 files\n",
    "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.mp3'):\n",
    "            # Extract the text from the MP3 file\n",
    "            mp3_path = os.path.join(dirpath, filename)\n",
    "            text = extract_text_from_mp3(mp3_path)\n",
    "            texts.append(text)\n",
    "\n",
    "# Print the extracted texts\n",
    "for text in texts:\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "664be334",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\siddh\\\\MY PYTHON\\\\Machine_Learning_Practice_2023\\\\MachineLearning\\\\AML_Project\\\\audio\\\\af'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9308\\3135437155.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"C:\\Users\\siddh\\MY PYTHON\\Machine_Learning_Practice_2023\\MachineLearning\\AML_Project\\audio\\af\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mextract_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_linguistic_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9308\\3135437155.py\u001b[0m in \u001b[0;36mextract_text\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Transcribe audio to text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecognizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;31m# attempt to read the file as WAV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename_or_fileobject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlittle_endian\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# RIFF WAV is a little-endian format (most ``audioop`` operations assume that the frames are stored in little-endian form)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwave\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mWave_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\wave.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_i_opened_the_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[1;31m# else, assume it is an open file object already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\siddh\\\\MY PYTHON\\\\Machine_Learning_Practice_2023\\\\MachineLearning\\\\AML_Project\\\\audio\\\\af'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import speech_recognition as sr\n",
    "\n",
    "def extract_text(audio_path):\n",
    "    # Convert audio file to WAV format\n",
    "    if audio_path.endswith('.mp3'):\n",
    "        wav_path = os.path.splitext(audio_path)[0] + '.wav'\n",
    "        subprocess.call(['ffmpeg', '-i', audio_path, '-vn', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', wav_path])\n",
    "    else:\n",
    "        wav_path = audio_path\n",
    "        # Transcribe audio to text\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(wav_path) as source:\n",
    "        audio = r.record(source)\n",
    "    text = r.recognize_google(audio)\n",
    "    return text\n",
    "path = r\"C:\\Users\\siddh\\MY PYTHON\\Machine_Learning_Practice_2023\\MachineLearning\\AML_Project\\audio\\af\"\n",
    "extract_text(path)\n",
    "\n",
    "def extract_linguistic_features(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Use spaCy to extract linguistic features from the text\n",
    "    doc = nlp(text)\n",
    "    features = {\n",
    "        \"num_sentences\": len(list(doc.sents)),\n",
    "        \"num_words\": len(doc),\n",
    "        \"num_unique_words\": len(set([token.text.lower() for token in doc if token.is_alpha])),\n",
    "        \"avg_word_length\": sum([len(token.text) for token in doc if token.is_alpha]) / len([token for token in doc if token.is_alpha]),\n",
    "        \"num_stopwords\": len([token for token in doc if token.is_stop]),\n",
    "        \"avg_sentence_length\": len(doc) / len(list(doc.sents)),\n",
    "        \"num_nouns\": len([token for token in doc if token.pos_ == \"NOUN\"]),\n",
    "        \"num_verbs\": len([token for token in doc if token.pos_ == \"VERB\"]),\n",
    "        \"num_adjectives\": len([token for token in doc if token.pos_ == \"ADJ\"]),\n",
    "        \"num_adverbs\": len([token for token in doc if token.pos_ == \"ADV\"]),\n",
    "        \"num_pronouns\": len([token for token in doc if token.pos_ == \"PRON\"]),\n",
    "        \"num_proper_nouns\": len([token for token in doc if token.pos_ == \"PROPN\"]),\n",
    "        \"num_conjunctions\": len([token for token in doc if token.pos_ == \"CCONJ\" or token.pos_ == \"SCONJ\"]),\n",
    "        \"num_numerals\": len([token for token in doc if token.pos_ == \"NUM\"]),\n",
    "        \"num_particles\": len([token for token in doc if token.pos_ == \"PART\"]),\n",
    "        \"num_punctuations\": len([token for token in doc if token.pos_ == \"PUNCT\"]),\n",
    "        \"num_symbols\": len([token for token in doc if token.pos_ == \"SYM\"])\n",
    "    }\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a34c17b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file audio\\af\\kooch.mp3: \n",
      "Processing file: audio\\af\\kootch.mp3\n",
      "Error processing file audio\\af\\kootch.mp3: \n",
      "Processing file: audio\\af\\kraut.mp3\n",
      "Error processing file audio\\af\\kraut.mp3: \n",
      "Processing file: audio\\af\\kunt.mp3\n",
      "Error processing file audio\\af\\kunt.mp3: \n",
      "Processing file: audio\\af\\kyke.mp3\n",
      "Error processing file audio\\af\\kyke.mp3: \n",
      "Processing file: audio\\af\\lameass.mp3\n",
      "Error processing file audio\\af\\lameass.mp3: \n",
      "Processing file: audio\\af\\lardass.mp3\n",
      "Error processing file audio\\af\\lardass.mp3: \n",
      "Processing file: audio\\af\\lesbian.mp3\n",
      "Error processing file audio\\af\\lesbian.mp3: \n",
      "Processing file: audio\\af\\lesbo.mp3\n",
      "Error processing file audio\\af\\lesbo.mp3: \n",
      "Processing file: audio\\af\\lezzie.mp3\n",
      "Error processing file audio\\af\\lezzie.mp3: \n",
      "Processing file: audio\\af\\mcfagget.mp3\n",
      "Error processing file audio\\af\\mcfagget.mp3: \n",
      "Processing file: audio\\af\\mick.mp3\n",
      "Error processing file audio\\af\\mick.mp3: \n",
      "Processing file: audio\\af\\minge.mp3\n",
      "Error processing file audio\\af\\minge.mp3: \n",
      "Processing file: audio\\af\\mothafucka.mp3\n",
      "Error processing file audio\\af\\mothafucka.mp3: \n",
      "Processing file: audio\\af\\motherfucker.mp3\n",
      "Error processing file audio\\af\\motherfucker.mp3: \n",
      "Processing file: audio\\af\\motherfucking.mp3\n",
      "Error processing file audio\\af\\motherfucking.mp3: \n",
      "Processing file: audio\\af\\muff.mp3\n",
      "Error processing file audio\\af\\muff.mp3: \n",
      "Processing file: audio\\af\\muffdiver.mp3\n",
      "Error processing file audio\\af\\muffdiver.mp3: \n",
      "Processing file: audio\\af\\munging.mp3\n",
      "Error processing file audio\\af\\munging.mp3: \n",
      "Processing file: audio\\af\\negro.mp3\n",
      "Error processing file audio\\af\\negro.mp3: \n",
      "Processing file: audio\\af\\nigaboo.mp3\n",
      "Error processing file audio\\af\\nigaboo.mp3: \n",
      "Processing file: audio\\af\\nigga.mp3\n",
      "Error processing file audio\\af\\nigga.mp3: \n",
      "Processing file: audio\\af\\nigger.mp3\n",
      "Error processing file audio\\af\\nigger.mp3: \n",
      "Processing file: audio\\af\\niggers.mp3\n",
      "Error processing file audio\\af\\niggers.mp3: \n",
      "Processing file: audio\\af\\niglet.mp3\n",
      "Error processing file audio\\af\\niglet.mp3: \n",
      "Processing file: audio\\af\\nut sack.mp3\n",
      "Error processing file audio\\af\\nut sack.mp3: \n",
      "Processing file: audio\\af\\nutsack.mp3\n",
      "Error processing file audio\\af\\nutsack.mp3: \n",
      "Processing file: audio\\af\\paki.mp3\n",
      "Error processing file audio\\af\\paki.mp3: \n",
      "Processing file: audio\\af\\panooch.mp3\n",
      "Error processing file audio\\af\\panooch.mp3: \n",
      "Processing file: audio\\af\\pecker.mp3\n",
      "Error processing file audio\\af\\pecker.mp3: \n",
      "Processing file: audio\\af\\peckerhead.mp3\n",
      "Error processing file audio\\af\\peckerhead.mp3: \n",
      "Processing file: audio\\af\\penis.mp3\n",
      "Error processing file audio\\af\\penis.mp3: \n",
      "Processing file: audio\\af\\penisbanger.mp3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9308\\2074016949.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;31m# Convert audio to text and extract features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                 \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m                 \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_linguistic_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Transcribed text: {text}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9308\\2074016949.py\u001b[0m in \u001b[0;36mextract_text\u001b[1;34m(audio_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAudioFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\speech_recognition\\__init__.py\u001b[0m in \u001b[0;36mrecognize_google\u001b[1;34m(self, audio_data, key, language, pfilter, show_all, with_confidence)\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;31m# obtain audio transcription results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moperation_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    709\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRequestError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"recognition request failed: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# post-process response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    535\u001b[0m                                   '_open', req)\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import speech_recognition as sr\n",
    "import spacy\n",
    "\n",
    "def extract_text(audio_path):\n",
    "    # Convert audio file to WAV format\n",
    "    if audio_path.endswith('.mp3'):\n",
    "        wav_path = os.path.splitext(audio_path)[0] + '.wav'\n",
    "        subprocess.call(['ffmpeg', '-i', audio_path, '-vn', '-acodec', 'pcm_s16le', '-ac', '1', '-ar', '16000', wav_path])\n",
    "    else:\n",
    "        wav_path = audio_path\n",
    "    \n",
    "    # Transcribe audio to text\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(wav_path) as source:\n",
    "        audio = r.record(source)\n",
    "    text = r.recognize_google(audio)\n",
    "    return text\n",
    "\n",
    "def extract_linguistic_features(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Use spaCy to extract linguistic features from the text\n",
    "    doc = nlp(text)\n",
    "    features = {\n",
    "        \"num_sentences\": len(list(doc.sents)),\n",
    "        \"num_words\": len(doc),\n",
    "        \"num_unique_words\": len(set([token.text.lower() for token in doc if token.is_alpha])),\n",
    "        \"avg_word_length\": sum([len(token.text) for token in doc if token.is_alpha]) / len([token for token in doc if token.is_alpha]),\n",
    "        \"num_stopwords\": len([token for token in doc if token.is_stop]),\n",
    "        \"avg_sentence_length\": len(doc) / len(list(doc.sents)),\n",
    "        \"num_nouns\": len([token for token in doc if token.pos_ == \"NOUN\"]),\n",
    "        \"num_verbs\": len([token for token in doc if token.pos_ == \"VERB\"]),\n",
    "        \"num_adjectives\": len([token for token in doc if token.pos_ == \"ADJ\"]),\n",
    "        \"num_adverbs\": len([token for token in doc if token.pos_ == \"ADV\"]),\n",
    "        \"num_pronouns\": len([token for token in doc if token.pos_ == \"PRON\"]),\n",
    "        \"num_proper_nouns\": len([token for token in doc if token.pos_ == \"PROPN\"]),\n",
    "        \"num_conjunctions\": len([token for token in doc if token.pos_ == \"CCONJ\" or token.pos_ == \"SCONJ\"]),\n",
    "        \"num_numerals\": len([token for token in doc if token.pos_ == \"NUM\"]),\n",
    "        \"num_particles\": len([token for token in doc if token.pos_ == \"PART\"]),\n",
    "        \"num_punctuations\": len([token for token in doc if token.pos_ == \"PUNCT\"]),\n",
    "        \"num_symbols\": len([token for token in doc if token.pos_ == \"SYM\"])\n",
    "    }\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Traverse through all subdirectories of \"audio\" folder\n",
    "for root, dirs, files in os.walk(\"audio\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".mp3\"):\n",
    "            audio_path = os.path.join(root, file)\n",
    "            print(f\"Processing file: {audio_path}\")\n",
    "            \n",
    "            # Convert audio to text and extract features\n",
    "            try:\n",
    "                text = extract_text(audio_path)\n",
    "                features = extract_linguistic_features(text)\n",
    "                print(f\"Transcribed text: {text}\")\n",
    "                print(f\"Extracted features: {features}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {audio_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968743ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
