{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53533137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d3ee66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\AppData\\Local\\Temp\\ipykernel_5832\\2174132205.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv('movie_lines.tsv', sep='\\t', encoding='ISO-8859-1', error_bad_lines=False)\n",
      "Skipping line 32288: expected 5 fields, saw 7\n",
      "Skipping line 32351: expected 5 fields, saw 6\n",
      "Skipping line 32390: expected 5 fields, saw 6\n",
      "Skipping line 32583: expected 5 fields, saw 6\n",
      "Skipping line 32585: expected 5 fields, saw 6\n",
      "Skipping line 35684: expected 5 fields, saw 6\n",
      "Skipping line 62132: expected 5 fields, saw 6\n",
      "Skipping line 86637: expected 5 fields, saw 6\n",
      "Skipping line 86722: expected 5 fields, saw 6\n",
      "Skipping line 86914: expected 5 fields, saw 6\n",
      "Skipping line 86960: expected 5 fields, saw 6\n",
      "Skipping line 87010: expected 5 fields, saw 6\n",
      "Skipping line 87011: expected 5 fields, saw 6\n",
      "Skipping line 87086: expected 5 fields, saw 6\n",
      "Skipping line 120607: expected 5 fields, saw 6\n",
      "Skipping line 120719: expected 5 fields, saw 7\n",
      "Skipping line 120739: expected 5 fields, saw 6\n",
      "Skipping line 120783: expected 5 fields, saw 6\n",
      "Skipping line 130284: expected 5 fields, saw 7\n",
      "Skipping line 131048: expected 5 fields, saw 6\n",
      "\n",
      "Skipping line 150955: expected 5 fields, saw 8\n",
      "Skipping line 162777: expected 5 fields, saw 11\n",
      "Skipping line 162778: expected 5 fields, saw 11\n",
      "Skipping line 162830: expected 5 fields, saw 9\n",
      "Skipping line 162864: expected 5 fields, saw 11\n",
      "Skipping line 162883: expected 5 fields, saw 8\n",
      "Skipping line 190170: expected 5 fields, saw 6\n",
      "Skipping line 195924: expected 5 fields, saw 6\n",
      "Skipping line 196054: expected 5 fields, saw 6\n",
      "Skipping line 196088: expected 5 fields, saw 6\n",
      "Skipping line 200335: expected 5 fields, saw 6\n",
      "Skipping line 200453: expected 5 fields, saw 6\n",
      "Skipping line 200863: expected 5 fields, saw 6\n",
      "Skipping line 200913: expected 5 fields, saw 6\n",
      "Skipping line 200934: expected 5 fields, saw 6\n",
      "Skipping line 200991: expected 5 fields, saw 6\n",
      "Skipping line 209214: expected 5 fields, saw 6\n",
      "Skipping line 209271: expected 5 fields, saw 6\n",
      "Skipping line 212476: expected 5 fields, saw 17\n",
      "Skipping line 212477: expected 5 fields, saw 12\n",
      "Skipping line 212490: expected 5 fields, saw 12\n",
      "Skipping line 212493: expected 5 fields, saw 10\n",
      "Skipping line 212514: expected 5 fields, saw 9\n",
      "Skipping line 212515: expected 5 fields, saw 12\n",
      "Skipping line 212556: expected 5 fields, saw 12\n",
      "Skipping line 212562: expected 5 fields, saw 8\n",
      "Skipping line 212567: expected 5 fields, saw 12\n",
      "Skipping line 212575: expected 5 fields, saw 12\n",
      "Skipping line 212582: expected 5 fields, saw 14\n",
      "Skipping line 212595: expected 5 fields, saw 11\n",
      "Skipping line 212600: expected 5 fields, saw 8\n",
      "Skipping line 212652: expected 5 fields, saw 11\n",
      "Skipping line 212655: expected 5 fields, saw 8\n",
      "Skipping line 212696: expected 5 fields, saw 9\n",
      "Skipping line 212700: expected 5 fields, saw 35\n",
      "Skipping line 212704: expected 5 fields, saw 9\n",
      "Skipping line 212736: expected 5 fields, saw 26\n",
      "Skipping line 212737: expected 5 fields, saw 12\n",
      "Skipping line 212738: expected 5 fields, saw 34\n",
      "Skipping line 212740: expected 5 fields, saw 7\n",
      "Skipping line 212741: expected 5 fields, saw 11\n",
      "Skipping line 212742: expected 5 fields, saw 11\n",
      "Skipping line 212743: expected 5 fields, saw 12\n",
      "Skipping line 212744: expected 5 fields, saw 11\n",
      "Skipping line 212745: expected 5 fields, saw 10\n",
      "Skipping line 212746: expected 5 fields, saw 17\n",
      "Skipping line 212747: expected 5 fields, saw 10\n",
      "Skipping line 212748: expected 5 fields, saw 21\n",
      "Skipping line 212749: expected 5 fields, saw 14\n",
      "Skipping line 212755: expected 5 fields, saw 9\n",
      "Skipping line 212756: expected 5 fields, saw 10\n",
      "Skipping line 212757: expected 5 fields, saw 14\n",
      "Skipping line 212758: expected 5 fields, saw 10\n",
      "Skipping line 212759: expected 5 fields, saw 7\n",
      "Skipping line 212760: expected 5 fields, saw 17\n",
      "Skipping line 212768: expected 5 fields, saw 9\n",
      "Skipping line 212774: expected 5 fields, saw 12\n",
      "Skipping line 212775: expected 5 fields, saw 11\n",
      "Skipping line 212784: expected 5 fields, saw 11\n",
      "Skipping line 212790: expected 5 fields, saw 29\n",
      "Skipping line 212791: expected 5 fields, saw 12\n",
      "Skipping line 212888: expected 5 fields, saw 12\n",
      "Skipping line 212895: expected 5 fields, saw 7\n",
      "Skipping line 212901: expected 5 fields, saw 8\n",
      "Skipping line 212909: expected 5 fields, saw 21\n",
      "Skipping line 212910: expected 5 fields, saw 19\n",
      "Skipping line 212912: expected 5 fields, saw 19\n",
      "Skipping line 212913: expected 5 fields, saw 14\n",
      "Skipping line 212914: expected 5 fields, saw 19\n",
      "Skipping line 212915: expected 5 fields, saw 19\n",
      "Skipping line 212916: expected 5 fields, saw 12\n",
      "Skipping line 212918: expected 5 fields, saw 18\n",
      "Skipping line 220002: expected 5 fields, saw 6\n",
      "Skipping line 223476: expected 5 fields, saw 6\n",
      "Skipping line 223670: expected 5 fields, saw 6\n",
      "Skipping line 227241: expected 5 fields, saw 6\n",
      "Skipping line 227687: expected 5 fields, saw 6\n",
      "Skipping line 227795: expected 5 fields, saw 6\n",
      "Skipping line 227850: expected 5 fields, saw 6\n",
      "Skipping line 228956: expected 5 fields, saw 6\n",
      "Skipping line 229142: expected 5 fields, saw 6\n",
      "Skipping line 229252: expected 5 fields, saw 6\n",
      "Skipping line 229283: expected 5 fields, saw 6\n",
      "Skipping line 229343: expected 5 fields, saw 6\n",
      "Skipping line 237190: expected 5 fields, saw 6\n",
      "Skipping line 237212: expected 5 fields, saw 6\n",
      "Skipping line 237475: expected 5 fields, saw 6\n",
      "Skipping line 237680: expected 5 fields, saw 6\n",
      "Skipping line 239909: expected 5 fields, saw 6\n",
      "Skipping line 242513: expected 5 fields, saw 6\n",
      "Skipping line 242621: expected 5 fields, saw 6\n",
      "Skipping line 252471: expected 5 fields, saw 10\n",
      "Skipping line 254823: expected 5 fields, saw 6\n",
      "Skipping line 257362: expected 5 fields, saw 6\n",
      "Skipping line 260304: expected 5 fields, saw 11\n",
      "Skipping line 261241: expected 5 fields, saw 11\n",
      "Skipping line 261309: expected 5 fields, saw 6\n",
      "Skipping line 261343: expected 5 fields, saw 6\n",
      "Skipping line 261432: expected 5 fields, saw 6\n",
      "Skipping line 261461: expected 5 fields, saw 6\n",
      "Skipping line 261520: expected 5 fields, saw 14\n",
      "Skipping line 261521: expected 5 fields, saw 13\n",
      "Skipping line 261525: expected 5 fields, saw 13\n",
      "Skipping line 261533: expected 5 fields, saw 6\n",
      "Skipping line 261558: expected 5 fields, saw 7\n",
      "Skipping line 261560: expected 5 fields, saw 7\n",
      "Skipping line 262063: expected 5 fields, saw 6\n",
      "Skipping line 262098: expected 5 fields, saw 6\n",
      "\n",
      "Skipping line 269343: expected 5 fields, saw 6\n",
      "Skipping line 269435: expected 5 fields, saw 6\n",
      "Skipping line 278994: expected 5 fields, saw 9\n",
      "Skipping line 278995: expected 5 fields, saw 9\n",
      "Skipping line 278996: expected 5 fields, saw 15\n",
      "Skipping line 279001: expected 5 fields, saw 15\n",
      "Skipping line 279038: expected 5 fields, saw 16\n",
      "Skipping line 279040: expected 5 fields, saw 10\n",
      "Skipping line 279041: expected 5 fields, saw 19\n",
      "Skipping line 279045: expected 5 fields, saw 13\n",
      "Skipping line 279047: expected 5 fields, saw 9\n",
      "Skipping line 279058: expected 5 fields, saw 10\n",
      "Skipping line 279069: expected 5 fields, saw 11\n",
      "Skipping line 279087: expected 5 fields, saw 11\n",
      "Skipping line 279094: expected 5 fields, saw 12\n",
      "Skipping line 279116: expected 5 fields, saw 22\n",
      "Skipping line 279131: expected 5 fields, saw 16\n",
      "Skipping line 279152: expected 5 fields, saw 10\n",
      "Skipping line 279155: expected 5 fields, saw 19\n",
      "Skipping line 279159: expected 5 fields, saw 9\n",
      "Skipping line 279199: expected 5 fields, saw 36\n",
      "Skipping line 279211: expected 5 fields, saw 9\n",
      "Skipping line 279213: expected 5 fields, saw 13\n",
      "Skipping line 279214: expected 5 fields, saw 9\n",
      "Skipping line 279233: expected 5 fields, saw 14\n",
      "Skipping line 279253: expected 5 fields, saw 15\n",
      "Skipping line 279345: expected 5 fields, saw 13\n",
      "Skipping line 279346: expected 5 fields, saw 10\n",
      "Skipping line 279379: expected 5 fields, saw 9\n",
      "Skipping line 279434: expected 5 fields, saw 17\n",
      "Skipping line 279440: expected 5 fields, saw 14\n",
      "Skipping line 279442: expected 5 fields, saw 14\n",
      "Skipping line 279443: expected 5 fields, saw 10\n",
      "Skipping line 279452: expected 5 fields, saw 16\n",
      "Skipping line 279455: expected 5 fields, saw 9\n",
      "Skipping line 279456: expected 5 fields, saw 12\n",
      "Skipping line 279457: expected 5 fields, saw 10\n",
      "Skipping line 279458: expected 5 fields, saw 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the movie_lines.tsv file into a pandas dataframe\n",
    "data = pd.read_csv('movie_lines.tsv', sep='\\t', encoding='ISO-8859-1', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5b1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['lineID', 'characterID', 'movieID', 'character', 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fa07833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90e2e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map each label to a number\n",
    "labels = ['not hate', 'hate']\n",
    "label_dict = {}\n",
    "for index, label in enumerate(labels):\n",
    "    label_dict[label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2490f5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the labels to numbers\n",
    "data['label'] = data['text'].apply(lambda x: label_dict['hate'] if 'hate' in x.lower() else label_dict['not hate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062d76fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_df = data[:train_size]\n",
    "test_df = data[train_size:]\n",
    "\n",
    "# Set the maximum number of words and sequence length\n",
    "max_words = 10000\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0782482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13f44bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to the same length\n",
    "train_data = pad_sequences(train_sequences, maxlen=max_len)\n",
    "test_data = pad_sequences(test_sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b56820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the NLP model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(max_words, 128, input_length=max_len),\n",
    "    tf.keras.layers.Conv1D(32, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=4),\n",
    "    tf.keras.layers.LSTM(128),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cff7872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7216/7216 [==============================] - 453s 63ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 7.0504e-04 - val_accuracy: 0.9999\n",
      "1804/1804 [==============================] - 34s 19ms/step - loss: 7.0504e-04 - accuracy: 0.9999\n",
      "Test accuracy: 0.9999306797981262\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_df['label'], epochs=1, validation_data=(test_data, test_df['label']))\n",
    "\n",
    "# Test the model\n",
    "loss, accuracy = model.evaluate(test_data, test_df['label'])\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "726bdb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('speech_censorship_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bc0cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= train_data\n",
    "y_train= train_df['label']\n",
    "X_test= test_data\n",
    "y_test= test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5b2aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32c8a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1804/1804 [==============================] - 32s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd8db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert continuous targets to binary targets\n",
    "threshold = 0.5\n",
    "y_test_binary = np.array([1 if p > threshold else 0 for p in y_test])\n",
    "y_pred_binary = np.array([1 if p > threshold else 0 for p in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc29e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "precision = precision_score(y_test_binary, y_pred_binary)\n",
    "f1 = f1_score(y_test_binary, y_pred_binary)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_binary, y_pred_binary).ravel()\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "fnr = fn / (fn + tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84de6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999307047328667\n",
      "Precision: 1.0\n",
      "F1-score: 0.9945652173913043\n",
      "True positive rate (TPR): 0.9891891891891892\n",
      "False positive rate (FPR): 0.0\n",
      "False negative rate (FNR): 0.010810810810810811\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1-score:\", f1)\n",
    "print(\"True positive rate (TPR):\", tpr)\n",
    "print(\"False positive rate (FPR):\", fpr)\n",
    "print(\"False negative rate (FNR):\", fnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ce9b3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Hate speech\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I HATE YOU\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "sentence_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "# Pad the sequence to the same length as the training data\n",
    "padded_sequence = pad_sequences(sentence_sequence, maxlen=max_len)\n",
    "\n",
    "# Predict the label of the sentence\n",
    "predicted_label = model.predict(padded_sequence)[0][0]\n",
    "if predicted_label > threshold:\n",
    "    print(\"Hate speech\")\n",
    "else:\n",
    "    print(\"Not hate speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd33702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Not hate speech\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I can't stand spicy food.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "sentence_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "# Pad the sequence to the same length as the training data\n",
    "padded_sequence = pad_sequences(sentence_sequence, maxlen=max_len)\n",
    "\n",
    "# Predict the label of the sentence\n",
    "predicted_label = model.predict(padded_sequence)[0][0]\n",
    "if predicted_label > threshold:\n",
    "    print(\"Hate speech\")\n",
    "else:\n",
    "    print(\"Not hate speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0ba1815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Hate speech\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I hate going to the dentist.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "sentence_sequence = tokenizer.texts_to_sequences([sentence])\n",
    "\n",
    "# Pad the sequence to the same length as the training data\n",
    "padded_sequence = pad_sequences(sentence_sequence, maxlen=max_len)\n",
    "\n",
    "# Predict the label of the sentence\n",
    "predicted_label = model.predict(padded_sequence)[0][0]\n",
    "if predicted_label > threshold:\n",
    "    print(\"Hate speech\")\n",
    "else:\n",
    "    print(\"Not hate speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f3b15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
